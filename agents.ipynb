{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Done\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# from langchain.agents import AgentType, initialize_agent\n",
    "from langchain.tools import Tool\n",
    "from langchain import SerpAPIWrapper\n",
    "from langchain.chat_models import ChatOpenAI, ChatGooglePalm, ChatVertexAI\n",
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain, LLMChain\n",
    "# from langchain.agents import AgentExecutor\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_groq import ChatGroq\n",
    "from tools import retrival_question_answering\n",
    "import streamlit as st\n",
    "from utilities import *\n",
    "from prompts import *\n",
    "import uuid\n",
    "import json\n",
    "\n",
    "set_API(name=\"chatgroq\", platform=\"c\")\n",
    "set_API(name=\"huggingface\", platform=\"hf\")\n",
    "set_API(name=\"serpapi\", platform=\"s\")\n",
    "\n",
    "dict_ignore_files = {\n",
    "    \"dir\": [\".github\", \".git\", \".devcontainer\", \"docs\", \"examples\", \"sample_documents\"],\n",
    "    \"extension\": [\"faiss\", \"pdf\", \"cff\",\"png\", \"jpg\", \"gif\", \"yaml\", \"cff\", \"Dockerfile\", \"lock\", \"toml\", \"odt\", \"gitmodules\", \"csv\", \"example\", \"ambr\", \"html\", \"typed\", \"xml\", \"yml\", \"avi\"],\n",
    "    \"file\": [\".gitignore\", \".dockerignore\", \".flake8\", \".gitattributes\", \"Dockerfile\", \"LICENSE\", \"Makefile\"]\n",
    "}\n",
    "# st.title(\"DirectoryGenius Chatbot Omega\")\n",
    "model2 = ChatGroq( model_name=\"Llama3-70b-8192\")#Mixtral-8x7b-32768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roy/miniconda3/envs/PyTorch_env/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embedd_model = \"all-mpnet-base-v2\"\n",
    "cache_folder_name = \"cache/mpnet-base-v2\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=embedd_model, cache_folder=cache_folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a68f23d9beda484788b0a0e56b4e0385",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bffa61e5942b4387bc6e83b8cf6409ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "folder_path = \"/home/roy/GSOC/TV-News-Chat-LLM\"\n",
    "strut_file_path = dir_structure(path_to_dir = folder_path, ignore_files = {\"dir\": [], \"extension\": [], \"file\": []})\n",
    "summary_file_path = summarize_and_write(path_to_dir=folder_path, ignore_files = dict_ignore_files, llm = \"Llama3-70b-8192\")\n",
    "databasename = folder_path.split(\"/\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeb6dbfbc2524ab0a635b844b962c69a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5140740347ed47f2bfadfbb86d3a2167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedding function is deprecated and will be removed in the future. Please use embedding instead.\n",
      "Creating 173 embeddings in 1 batches of size 173:: 100%|██████████| 1/1 [00:08<00:00,  8.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='Database/TV-News-Chat-LLM-cache/mpnet-base-v2', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype      shape      dtype  compression\n",
      "  -------    -------    -------    -------  ------- \n",
      "   text       text      (173, 1)     str     None   \n",
      " metadata     json      (173, 1)     str     None   \n",
      " embedding  embedding  (173, 768)  float32   None   \n",
      "    id        text      (173, 1)     str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "files = Search2(path = folder_path, ignore=dict_ignore_files)\n",
    "Create_DB(files=files, database_path = f\"Database/{databasename}-{cache_folder_name}\", embeddings=embeddings)\n",
    "os.remove(strut_file_path)\n",
    "os.remove(summary_file_path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedding function is deprecated and will be removed in the future. Please use embedding instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Lake Dataset in Database/langchain-cache/mpnet-base-v2 already exists, loading from the storage\n"
     ]
    }
   ],
   "source": [
    "db2 = DeepLake(dataset_path=f\"Database/{databasename}-{cache_folder_name}\", read_only=True, embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db2.as_retriever()\n",
    "retriever.search_kwargs['distance_metric'] = 'cos'\n",
    "retriever.search_kwargs['fetch_k'] = 100\n",
    "# retriever.search_kwargs['maximal_marginal_relevance'] = True\n",
    "retriever.search_kwargs['k'] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_GUI(file: str):#, application: str = \"xdg-open\"):\n",
    "\n",
    "    os.system(f\"xdg-open {file}\")\n",
    "\n",
    "    \n",
    "def find_similar_files(string: str):\n",
    "\n",
    "    context = retriever.get_relevant_documents(string)\n",
    "    found = []\n",
    "    for cont in context:\n",
    "        found.append(cont.page_content)\n",
    "    if found:\n",
    "        return \"?\".join(found)\n",
    "    else:\n",
    "        return \"\"\n",
    "    \n",
    "def find_exact_files(string: str):\n",
    "    command = [\"grep\", \"-r\", string, \"Database/langchain/\"]\n",
    "    for dir in dict_ignore_files[\"dir\"]:\n",
    "        command.extend([f\"--exclude-dir={dir}\"])\n",
    "        # pass\n",
    "    # print(command)\n",
    "    result = subprocess.run(command, stdout=subprocess.PIPE).stdout.decode().split(\"\\n\")\n",
    "    if result:\n",
    "        files = map(lambda x: x.split(\":\")[0], result)\n",
    "        return \"?\".join(files)\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "serp_search = SerpAPIWrapper()\n",
    "tools = [\n",
    "    Tool.from_function(\n",
    "        func=open_GUI,\n",
    "        name = \"Open_file_in_editor\",\n",
    "        description=\"useful for when you need to open a file in editor\"\n",
    "        # coroutine= ... <- you can specify an async method if desired as well\n",
    "    ),\n",
    "    Tool.from_function(\n",
    "        func=find_exact_files,\n",
    "        name = \"Search_Exact_Files\",\n",
    "        description=\"useful for when you need to search for a code snippet in a database. in case no file is found, a empty string will be returned in case of more than one file, their names will be separated by '?' symbol.\"\n",
    "        # coroutine= ... <- you can specify an async method if desired as well\n",
    "    ),\n",
    "    Tool.from_function(\n",
    "        func=find_similar_files,\n",
    "        name = \"Search_Similar_Files\",\n",
    "        description=\"useful for when you need to search for a file related to some context and you don't have the exact keyword to search. in case of more than one file, their names will be separated by '?' symbol. in case no file is found, a empty string will be returned\"\n",
    "        # coroutine= ... <- you can specify an async method if desired as well\n",
    "    ),\n",
    "    Tool.from_function(\n",
    "        func=serp_search.run,\n",
    "        name = \"Search \",\n",
    "        description=\"useful when you need to search for a topic on internet. use it only when its absolute necessary.\"\n",
    "        # coroutine= ... <- you can specify an async method if desired as well\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2 = ChatGroq( model_name=\"Llama3-70b-8192\")#Mixtral-8x7b-32768\n",
    "memory = ConversationBufferMemory(\n",
    "    llm=model2,\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    "    max_token_limit=2000\n",
    ")\n",
    "# memory.output_key = 'result'\n",
    "# memory2 = ConversationSummaryBufferMemory(llm = model2,max_token_limit=200)\n",
    "# memory2.output_key = 'result'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "condense_title_chain = LLMChain(\n",
    "            llm=model2,\n",
    "            prompt=CONDENSE_title_PROMPT,\n",
    "            # verbose=verbose,\n",
    "            # callbacks=callbacks,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    model2,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    ")\n",
    "\n",
    "with open(\"chat_IDs.json\", \"w\") as file:\n",
    "        json.dump({\"details\": []}, file, indent = 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the provided file contents, here is the tree structure of the LangChain:\n",
       "```\n",
       "/home/roy/Langchain/langchain\n",
       "├── .folder_structure.md\n",
       "├── README.md\n",
       "├── libs\n",
       "│   └── langchain\n",
       "│       ├── __init__.py\n",
       "│       ├── chains\n",
       "│       │   ├── base.py\n",
       "│       │   └── llm.py\n",
       "│       ├── langchain\n",
       "│       │   ├── __init__.py\n",
       "│       │   └── smith\n",
       "│       │       └── evaluation.py\n",
       "│       ├── langchain_core\n",
       "│       │   ├── __init__.py\n",
       "│       │   ├── language_models\n",
       "│       │   │   └── llms\n",
       "│       │   │       └── base.py\n",
       "│       │   ├── load\n",
       "│       │   │   ├── __init__.py\n",
       "│       │   │   └── dump.py\n",
       "│       │   ├── messages\n",
       "│       │   │   └── base.py\n",
       "│       │   ├── outputs\n",
       "│       │   │   └── base.py\n",
       "│       │   ├── prompts\n",
       "│       │   │   └── prompt.py\n",
       "│       │   ├── retrievers\n",
       "│       │   │   └── base.py\n",
       "│       │   ├── schema\n",
       "│       │   │   └── base.py\n",
       "│       │   ├── utils\n",
       "│       │   │   ├── __init__.py\n",
       "│       │   │   ├── env.py\n",
       "│       │   │   ├── formatting.py\n",
       "│       │   │   ├── input.py\n",
       "│       │   │   ├── loading.py\n",
       "│       │   │   └── strings.py\n",
       "│       │   └── _api.py\n",
       "│       └── cookbook\n",
       "│           ├── causal_program_aided_language_model.ipynb\n",
       "│           ├── langgraph_crag.ipynb\n",
       "│           └── langgraph_self_rag.ipynb\n",
       "```\n",
       "Note that this structure might not be exhaustive, as not all files and directories might be present in the provided content.\n",
       "\n",
       "If you have any further questions or need clarification on any specific part of the structure, feel free to ask! "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"show the tree structure of the langchain\"\n",
    "reply = qa_chain({\"query\": question} )\n",
    "display_output(reply[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roy/miniconda3/envs/PyTorch_env/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00munique_id1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      6\u001b[0m         json\u001b[38;5;241m.\u001b[39mdump({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m\"\u001b[39m: []}, file, indent \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m reply \u001b[38;5;241m=\u001b[39m qa_chain({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: question} )\n\u001b[1;32m      8\u001b[0m text \u001b[38;5;241m=\u001b[39m condense_title_chain({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: question, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreply\u001b[39m\u001b[38;5;124m\"\u001b[39m : reply[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m]})\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat_IDs.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
      "File \u001b[0;32m~/miniconda3/envs/PyTorch_env/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:148\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     emit_warning()\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/PyTorch_env/lib/python3.11/site-packages/langchain/chains/base.py:383\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \n\u001b[1;32m    353\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    376\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    381\u001b[0m }\n\u001b[0;32m--> 383\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[1;32m    384\u001b[0m     inputs,\n\u001b[1;32m    385\u001b[0m     cast(RunnableConfig, {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m}),\n\u001b[1;32m    386\u001b[0m     return_only_outputs\u001b[38;5;241m=\u001b[39mreturn_only_outputs,\n\u001b[1;32m    387\u001b[0m     include_run_info\u001b[38;5;241m=\u001b[39minclude_run_info,\n\u001b[1;32m    388\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/PyTorch_env/lib/python3.11/site-packages/langchain/chains/base.py:166\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    165\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    167\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m~/miniconda3/envs/PyTorch_env/lib/python3.11/site-packages/langchain/chains/base.py:156\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    155\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 156\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    159\u001b[0m     )\n\u001b[1;32m    161\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    162\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/PyTorch_env/lib/python3.11/site-packages/langchain/chains/retrieval_qa/base.py:142\u001b[0m, in \u001b[0;36mBaseRetrievalQA._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    138\u001b[0m accepts_run_manager \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_docs)\u001b[38;5;241m.\u001b[39mparameters\n\u001b[1;32m    140\u001b[0m )\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m accepts_run_manager:\n\u001b[0;32m--> 142\u001b[0m     docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_docs(question, run_manager\u001b[38;5;241m=\u001b[39m_run_manager)\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_docs(question)  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/PyTorch_env/lib/python3.11/site-packages/langchain/chains/retrieval_qa/base.py:254\u001b[0m, in \u001b[0;36mRetrievalQA._get_docs\u001b[0;34m(self, question, run_manager)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_docs\u001b[39m(\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    249\u001b[0m     question: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m    251\u001b[0m     run_manager: CallbackManagerForChainRun,\n\u001b[1;32m    252\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m    253\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get docs.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretriever\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[1;32m    255\u001b[0m         question, config\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_manager\u001b[38;5;241m.\u001b[39mget_child()}\n\u001b[1;32m    256\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/PyTorch_env/lib/python3.11/site-packages/langchain_core/retrievers.py:194\u001b[0m, in \u001b[0;36mBaseRetriever.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Invoke the retriever to get relevant documents.\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \n\u001b[1;32m    177\u001b[0m \u001b[38;5;124;03mMain entry point for synchronous retriever invocations.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;124;03m    retriever.invoke(\"query\")\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    193\u001b[0m config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m--> 194\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_relevant_documents(\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    196\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    197\u001b[0m     tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    198\u001b[0m     metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    199\u001b[0m     run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    201\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/PyTorch_env/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:148\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     emit_warning()\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/PyTorch_env/lib/python3.11/site-packages/langchain_core/retrievers.py:323\u001b[0m, in \u001b[0;36mBaseRetriever.get_relevant_documents\u001b[0;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    322\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_error(e)\n\u001b[0;32m--> 323\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    325\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_end(\n\u001b[1;32m    326\u001b[0m         result,\n\u001b[1;32m    327\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/PyTorch_env/lib/python3.11/site-packages/langchain_core/retrievers.py:316\u001b[0m, in \u001b[0;36mBaseRetriever.get_relevant_documents\u001b[0;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m _kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_arg_supported:\n\u001b[0;32m--> 316\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(\n\u001b[1;32m    317\u001b[0m         query, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs\n\u001b[1;32m    318\u001b[0m     )\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    320\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/PyTorch_env/lib/python3.11/site-packages/langchain_core/vectorstores.py:696\u001b[0m, in \u001b[0;36mVectorStoreRetriever._get_relevant_documents\u001b[0;34m(self, query, run_manager)\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_relevant_documents\u001b[39m(\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m, run_manager: CallbackManagerForRetrieverRun\n\u001b[1;32m    694\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m    695\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 696\u001b[0m         docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorstore\u001b[38;5;241m.\u001b[39msimilarity_search(query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_kwargs)\n\u001b[1;32m    697\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity_score_threshold\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    698\u001b[0m         docs_and_similarities \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    699\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorstore\u001b[38;5;241m.\u001b[39msimilarity_search_with_relevance_scores(\n\u001b[1;32m    700\u001b[0m                 query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_kwargs\n\u001b[1;32m    701\u001b[0m             )\n\u001b[1;32m    702\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/PyTorch_env/lib/python3.11/site-packages/langchain_community/vectorstores/deeplake.py:541\u001b[0m, in \u001b[0;36mDeepLake.similarity_search\u001b[0;34m(self, query, k, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimilarity_search\u001b[39m(\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    484\u001b[0m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    485\u001b[0m     k: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    487\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m    488\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;124;03m    Return docs most similar to query.\u001b[39;00m\n\u001b[1;32m    490\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;124;03m        List[Document]: List of Documents most similar to the query vector.\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_search(\n\u001b[1;32m    542\u001b[0m         query\u001b[38;5;241m=\u001b[39mquery,\n\u001b[1;32m    543\u001b[0m         k\u001b[38;5;241m=\u001b[39mk,\n\u001b[1;32m    544\u001b[0m         use_maximal_marginal_relevance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    545\u001b[0m         return_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    546\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    547\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/PyTorch_env/lib/python3.11/site-packages/langchain_community/vectorstores/deeplake.py:432\u001b[0m, in \u001b[0;36mDeepLake._search\u001b[0;34m(self, query, embedding, embedding_function, k, distance_metric, use_maximal_marginal_relevance, fetch_k, filter, return_score, exec_option, deep_memory, **kwargs)\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    427\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    428\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEither `embedding` or `embedding_function` needs to be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    429\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    430\u001b[0m         )\n\u001b[0;32m--> 432\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m _embedding_function(query) \u001b[38;5;28;01mif\u001b[39;00m query \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(embedding, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    435\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(embedding, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/miniconda3/envs/PyTorch_env/lib/python3.11/site-packages/langchain_community/embeddings/huggingface.py:113\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings.embed_query\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21membed_query\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    105\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute query embeddings using a HuggingFace transformer model.\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03m        Embeddings for the text.\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_documents([text])[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/PyTorch_env/lib/python3.11/site-packages/langchain_community/embeddings/huggingface.py:98\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings.embed_documents\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m     96\u001b[0m     sentence_transformers\u001b[38;5;241m.\u001b[39mSentenceTransformer\u001b[38;5;241m.\u001b[39mstop_multi_process_pool(pool)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mencode(\n\u001b[1;32m     99\u001b[0m         texts, show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshow_progress, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_kwargs\n\u001b[1;32m    100\u001b[0m     )\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/miniconda3/envs/PyTorch_env/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:512\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[1;32m    504\u001b[0m             features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[1;32m    505\u001b[0m                 (\n\u001b[1;32m    506\u001b[0m                     features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m                 \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    510\u001b[0m             )\n\u001b[0;32m--> 512\u001b[0m features \u001b[38;5;241m=\u001b[39m batch_to_device(features, device)\n\u001b[1;32m    513\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate(extra_features)\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/miniconda3/envs/PyTorch_env/lib/python3.11/site-packages/sentence_transformers/util.py:561\u001b[0m, in \u001b[0;36mbatch_to_device\u001b[0;34m(batch, target_device)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch[key], Tensor):\n\u001b[0;32m--> 561\u001b[0m         batch[key] \u001b[38;5;241m=\u001b[39m batch[key]\u001b[38;5;241m.\u001b[39mto(target_device)\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m batch\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "question = input(\"Ask query:\")\n",
    "content = {\"Human\": '',\n",
    "           \"Assistant\": ''}\n",
    "unique_id1 = uuid.uuid1()\n",
    "with open(f\"memory/{unique_id1}.json\", \"w\") as file:\n",
    "        json.dump({\"history\": []}, file, indent = 4)\n",
    "reply = qa_chain({\"query\": question} )\n",
    "text = condense_title_chain({\"question\": question, \"reply\" : reply[\"result\"]})\n",
    "with open(\"chat_IDs.json\", 'r') as file:\n",
    "        id = json.load(file)\n",
    "id[\"details\"].append({text[\"text\"]: str(unique_id1)})\n",
    "with open(\"chat_IDs.json\", \"w\") as file:\n",
    "        json.dump(id, file, indent = 4)\n",
    "while question:\n",
    "    result = qa_chain({\"query\": question} )\n",
    "    with open(f\"memory/{unique_id1}.json\", 'r') as file:\n",
    "        data = json.load(file)\n",
    "    print(data)\n",
    "    content[\"Human\"] = question\n",
    "    content[\"Assistant\"] = result[\"result\"]\n",
    "    data[\"history\"].append(content)\n",
    "    display_output(result=result[\"result\"])\n",
    "    with open(f\"memory/{unique_id1}.json\", \"w\") as file:\n",
    "        json.dump(data, file, indent = 4)\n",
    "    question = input(\"Ask query:\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Show me the whole tree structure of opencv directory make sure it include all the files',\n",
       " 'result': 'Here is the tree structure of the OpenCV directory:\\n```\\n/home/roy/Documents/Opencv/\\n.ipynb_checkpoints/\\n6_contour_and_shape_detection-checkpoint.ipynb\\n1_edges_and_gradients.ipynb\\n2_convolutions_and_morphological.ipynb\\n3_blurring_and_thresholding.ipynb\\n4_drawing_and_bitwise.ipynb\\n5_colour_detection.ipynb\\n6_contour_and_shape_detection.ipynb\\n7_mouse_events_and_wrap.ipynb\\n8_haarcascades.ipynb\\nutilities.py\\nassets/\\ncascades/\\nhaarcascade_smile.xml\\nhaarcascade_righteye_2splits.xml\\nhaarcascade_profileface.xml\\nhaarcascade_lowerbody.xml\\nhaarcascade_eye.xml\\nhaarcascade_frontalface_alt.xml\\nhaarcascade_russian_plate_number.xml\\nhaarcascade_fullbody.xml\\nhaarcascade_lefteye_2splits.xml\\nhaarcascade_eye_tree_eyeglasses.xml\\nhaarcascade_frontalcatface.xml\\nhaarcascade_upperbody.xml\\nhaarcascade_frontalface_alt2.xml\\nhaarcascade_frontalcatface_extended.xml\\nhaarcascade_frontalface_alt_tree.xml\\nhaarcascade_car.xml\\nhaarcascade_licence_plate_rus_16stages.xml\\nhaarcascade_frontalface_default.xml\\nimages/\\nshapes.jpg\\nrect.jpg\\nshapes_resize.jpg\\nhello.jpg\\nhello_noise_white.jpg\\nhello_noise_black.jpg\\nscenary.jpg\\nlenna.jpg\\nlamborgini_trackbar.png\\ntransform2.png\\nscharr.png\\nmapped.png\\nblank.png\\nthreshhold_type.png\\npage.jpg\\ncards.jpg\\ncards_points.png\\nopencv_noise.jpg\\nexamples kernels.png\\nfaces_resize.jpg\\nvideos/\\nwalking.avi\\ncars.avi\\noutput.avi\\ndoc.py\\ndataset_lock.lock\\n.folder_structure.md\\n```\\nNote that this tree structure includes all the files and directories mentioned in the provided content. Let me know if you have any further questions!',\n",
       " 'source_documents': [Document(page_content='The following  below content are from the the given file:\\n            [\\n            filename: .folder_structure.md\\n            filepath: /home/roy/Documents/Opencv/.folder_structure.md\\n            content: [And here is the Tree structure of the folder, Use it when asked for relative path or to print tree structure of the folder]\\n            ]\\n\\n\\n\\nThe following  below content are from the the given file:\\n            [\\n            filename: doc.py\\n            filepath: /home/roy/Documents/Opencv/assets/doc.py\\n            content: [# encoding: utf-8\\n# module cv2\\n# from /usr/lib/python3/dist-packages/cv2.cpython-38-x86_64-linux-gnu.so\\n# by generator 1.147\\n\"\"\" Python wrapper for OpenCV. \"\"\"]\\n            ]', metadata={'source': '/home/roy/Documents/Opencv/._folder_files_summary.txt'}),\n",
       "  Document(page_content='The following  below content are from the the given file:\\n            [\\n            filename: .folder_structure.md\\n            filepath: /home/roy/Documents/Opencv/.folder_structure.md', metadata={'source': '/home/roy/Documents/Opencv/._folder_files_summary.txt'}),\n",
       "  Document(page_content='The following  below content are from the the given file:\\n            [\\n            filename: .folder_structure.md\\n            filepath: /home/roy/Documents/Opencv/.folder_structure.md', metadata={'source': '/home/roy/Documents/Opencv/._folder_files_summary.txt'}),\n",
       "  Document(page_content='The following  below content are from the the given file:\\n            [\\n            filename: .folder_structure.md\\n            filepath: /home/roy/Documents/Opencv/.folder_structure.md', metadata={'source': '/home/roy/Documents/Opencv/._folder_files_summary.txt'}),\n",
       "  Document(page_content='The following  below content are from the the given file:\\n            [\\n            filename: .folder_structure.md\\n            filepath: /home/roy/Documents/Opencv/.folder_structure.md', metadata={'source': '/home/roy/Documents/Opencv/._folder_files_summary.txt'}),\n",
       "  Document(page_content='The following  below content are from the the given file:\\n            [\\n            filename: .folder_structure.md\\n            filepath: /home/roy/Documents/Opencv/.folder_structure.md', metadata={'source': '/home/roy/Documents/Opencv/._folder_files_summary.txt'}),\n",
       "  Document(page_content='And here is the Tree structure of the folder, Use it when asked for relative path or to print tree structure of the folder', metadata={'source': '/home/roy/Documents/Opencv/.folder_structure.md'}),\n",
       "  Document(page_content=\"[\\n            filename: .folder_structure.md\\n            filepath: /home/roy/Documents/Opencv/.folder_structure.md\\n            content: ['/home/roy/Documents/Opencv/assets/cascades/haarcascade_smile.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_righteye_2splits.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_profileface.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_lowerbody.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_eye.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_frontalface_alt.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_russian_plate_number.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_fullbody.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_lefteye_2splits.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_eye_tree_eyeglasses.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_frontalcatface.xml']]\\n            ]\", metadata={'source': '/home/roy/Documents/Opencv/._folder_files_summary.txt'}),\n",
       "  Document(page_content='Here is the list global paths of all the file in the directory:', metadata={'source': '/home/roy/Documents/Opencv/.folder_structure.md'}),\n",
       "  Document(page_content=\"['/home/roy/Documents/Opencv/.ipynb_checkpoints/6_contour_and_shape_detection-checkpoint.ipynb', '/home/roy/Documents/Opencv/5_colour_detection.ipynb', '/home/roy/Documents/Opencv/6_contour_and_shape_detection.ipynb', '/home/roy/Documents/Opencv/7_mouse_events_and_wrap.ipynb', '/home/roy/Documents/Opencv/1_edges_and_gradients.ipynb', '/home/roy/Documents/Opencv/2_convolutions_and_morphological.ipynb', '/home/roy/Documents/Opencv/8_haarcascades.ipynb', '/home/roy/Documents/Opencv/utilities.py', '/home/roy/Documents/Opencv/3_blurring_and_thresholding.ipynb', '/home/roy/Documents/Opencv/4_drawing_and_bitwise.ipynb', '/home/roy/Documents/Opencv/dataset_lock.lock', '/home/roy/Documents/Opencv/assets/doc.py', '/home/roy/Documents/Opencv/assets/videos/walking.avi', '/home/roy/Documents/Opencv/assets/videos/cars.avi', '/home/roy/Documents/Opencv/assets/videos/output.avi', '/home/roy/Documents/Opencv/assets/images/shapes.jpg', '/home/roy/Documents/Opencv/assets/images/rect.jpg',\", metadata={'source': '/home/roy/Documents/Opencv/.folder_structure.md'}),\n",
       "  Document(page_content=\"content: [['/home/roy/Documents/Opencv/.ipynb_checkpoints/6_contour_and_shape_detection-checkpoint.ipynb', '/home/roy/Documents/Opencv/5_colour_detection.ipynb', '/home/roy/Documents/Opencv/6_contour_and_shape_detection.ipynb', '/home/roy/Documents/Opencv/7_mouse_events_and_wrap.ipynb', '/home/roy/Documents/Opencv/1_edges_and_gradients.ipynb', '/home/roy/Documents/Opencv/2_convolutions_and_morphological.ipynb', '/home/roy/Documents/Opencv/8_haarcascades.ipynb', '/home/roy/Documents/Opencv/utilities.py', '/home/roy/Documents/Opencv/3_blurring_and_thresholding.ipynb', '/home/roy/Documents/Opencv/4_drawing_and_bitwise.ipynb', '/home/roy/Documents/Opencv/dataset_lock.lock', '/home/roy/Documents/Opencv/assets/doc.py', '/home/roy/Documents/Opencv/assets/videos/walking.avi', '/home/roy/Documents/Opencv/assets/videos/cars.avi', '/home/roy/Documents/Opencv/assets/videos/output.avi', '/home/roy/Documents/Opencv/assets/images/shapes.jpg', '/home/roy/Documents/Opencv/assets/images/rect.jpg',]\\n            ]\", metadata={'source': '/home/roy/Documents/Opencv/._folder_files_summary.txt'}),\n",
       "  Document(page_content=\"'/home/roy/Documents/Opencv/assets/images/transform2.png', '/home/roy/Documents/Opencv/assets/images/scharr.png', '/home/roy/Documents/Opencv/assets/images/mapped.png', '/home/roy/Documents/Opencv/assets/images/blank.png',]\", metadata={'source': '/home/roy/Documents/Opencv/._folder_files_summary.txt'}),\n",
       "  Document(page_content=\"'/home/roy/Documents/Opencv/assets/images/scharr.png', '/home/roy/Documents/Opencv/assets/images/mapped.png', '/home/roy/Documents/Opencv/assets/images/blank.png', '/home/roy/Documents/Opencv/assets/images/threshhold_type.png', '/home/roy/Documents/Opencv/assets/images/page.jpg', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_upperbody.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_frontalface_alt2.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_frontalcatface_extended.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_frontalface_alt_tree.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_car.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_licence_plate_rus_16stages.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_frontalface_default.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_smile.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_righteye_2splits.xml',\", metadata={'source': '/home/roy/Documents/Opencv/.folder_structure.md'}),\n",
       "  Document(page_content='# encoding: utf-8\\n# module cv2\\n# from /usr/lib/python3/dist-packages/cv2.cpython-38-x86_64-linux-gnu.so\\n# by generator 1.147\\n\"\"\" Python wrapper for OpenCV. \"\"\"', metadata={'source': '/home/roy/Documents/Opencv/assets/doc.py'}),\n",
       "  Document(page_content=\"'/home/roy/Documents/Opencv/assets/images/shapes_resize.jpg', '/home/roy/Documents/Opencv/assets/images/hello_noise_white.jpg', '/home/roy/Documents/Opencv/assets/images/hello.jpg', '/home/roy/Documents/Opencv/assets/images/sobel.png', '/home/roy/Documents/Opencv/assets/images/cards.jpg', '/home/roy/Documents/Opencv/assets/images/cards_points.png', '/home/roy/Documents/Opencv/assets/images/opencv_noise.jpg', '/home/roy/Documents/Opencv/assets/images/examples kernels.png', '/home/roy/Documents/Opencv/assets/images/faces_resize.jpg', '/home/roy/Documents/Opencv/assets/images/hello_noise_black.jpg', '/home/roy/Documents/Opencv/assets/images/scenary.jpg', '/home/roy/Documents/Opencv/assets/images/lenna.jpg', '/home/roy/Documents/Opencv/assets/images/lamborgini_trackbar.png', '/home/roy/Documents/Opencv/assets/images/transform2.png', '/home/roy/Documents/Opencv/assets/images/scharr.png', '/home/roy/Documents/Opencv/assets/images/mapped.png', '/home/roy/Documents/Opencv/assets/images/blank.png',\", metadata={'source': '/home/roy/Documents/Opencv/.folder_structure.md'}),\n",
       "  Document(page_content=\"content: ['/home/roy/Documents/Opencv/assets/images/scharr.png', '/home/roy/Documents/Opencv/assets/images/mapped.png', '/home/roy/Documents/Opencv/assets/images/blank.png', '/home/roy/Documents/Opencv/assets/images/threshhold_type.png', '/home/roy/Documents/Opencv/assets/images/page.jpg', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_upperbody.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_frontalface_alt2.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_frontalcatface_extended.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_frontalface_alt_tree.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_car.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_licence_plate_rus_16stages.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_frontalface_default.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_smile.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_righteye_2splits.xml',]\\n            ]\", metadata={'source': '/home/roy/Documents/Opencv/._folder_files_summary.txt'}),\n",
       "  Document(page_content='The following  below content are from the the given file:\\n            [\\n            filename: doc.py\\n            filepath: /home/roy/Documents/Opencv/assets/doc.py\\n            content: [.   #ConnectedComponentsTypes. The data type is CV_32S.\\n    .   @param centroids centroid output for each label, including the background label. Centroids are\\n    .   accessed via centroids(label, 0) for x and centroids(label, 1) for y. The data type CV_64F.\\n    .   @param connectivity 8 or 4 for 8-way or 4-way connectivity respectively\\n    .   @param ltype output image label type. Currently CV_32S and CV_16U are supported.\\n    .   @param ccltype connected components algorithm type (see #ConnectedComponentsAlgorithmsTypes).\\n    \"\"\"\\n    pass]\\n            ]', metadata={'source': '/home/roy/Documents/Opencv/._folder_files_summary.txt'}),\n",
       "  Document(page_content='The following  below content are from the the given file:\\n            [\\n            filename: doc.py\\n            filepath: /home/roy/Documents/Opencv/assets/doc.py\\n            content: [def findContours(image, mode, method, contours=None, hierarchy=None, offset=None): # real signature unknown; restored from __doc__\\n    \"\"\"\\n    findContours(image, mode, method[, contours[, hierarchy[, offset]]]) -> contours, hierarchy\\n    .   @brief Finds contours in a binary image.\\n    .   \\n    .   The function retrieves contours from the binary image using the algorithm @cite Suzuki85 . The contours\\n    .   are a useful tool for shape analysis and object detection and recognition. See squares.cpp in the\\n    .   OpenCV sample directory.\\n    .   @note Since opencv 3.2 source image is not modified by this function.\\n    .   \\n    .   @param image Source, an 8-bit single-channel image. Non-zero pixels are treated as 1\\'s. Zero', metadata={'source': '/home/roy/Documents/Opencv/._folder_files_summary.txt'}),\n",
       "  Document(page_content=\"'/home/roy/Documents/Opencv/assets/cascades/haarcascade_smile.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_righteye_2splits.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_profileface.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_lowerbody.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_eye.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_frontalface_alt.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_russian_plate_number.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_fullbody.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_lefteye_2splits.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_eye_tree_eyeglasses.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_frontalcatface.xml']\", metadata={'source': '/home/roy/Documents/Opencv/.folder_structure.md'}),\n",
       "  Document(page_content='The following  below content are from the the given file:\\n            [\\n            filename: utilities.py\\n            filepath: /home/roy/Documents/Opencv/utilities.py\\n            content: [if os.path.isfile(path) and (path.split(\".\")[-1].split(\"/\")[-1] not in ignore[\"extension\"]) and (path.split(\"/\") not in ignore[\"file\"]):\\n        return path\\n    elif os.path.isdir(path) and path.split(\"/\")[-1] not in ignore[\"dir\"]:\\n        files = []\\n        for p in os.listdir(path):\\n            if os.path.isfile(os.path.join(path, p)) and (p.split(\".\")[-1].split(\"/\")[-1] not in ignore[\"extension\"]) and (p.split(\"/\")[-1] not in ignore[\"file\"]):\\n                files.append(os.path.join(path, p))\\n            elif os.path.isdir(os.path.join(path, p)) and p.split(\"/\")[-1] not in ignore[\"dir\"]:\\n                files.extend(Search2(os.path.join(path, p), ignore=ignore))\\n\\n        if not(relative):\\n            cwd = os.getcwd() + os.path.sep\\n            files = list(map(lambda x: cwd + x, files))', metadata={'source': '/home/roy/Documents/Opencv/._folder_files_summary.txt'})]}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    model2,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    # verbose = True,\n",
    "    condense_question_prompt=CONDENSE_QUESTION_PROMPT,\n",
    "    # chain_type = \"stuff\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['question', 'chat_history']"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.input_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hello Aniruddha! It's nice to meet you. Is there something I can help you with or would you like to ask me a question? "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = {\"chat_history\": ''}\n",
    "question = \"Hello myself Aniruddha\"\n",
    "text = condense_question_chain({\"chat_history\": result[\"chat_history\"] , \"question\": question})\n",
    "\n",
    "result = qa({\"question\": text[\"text\"]})\n",
    "# memory.save_context({\"input\": result[\"chat_history\"][0::2]}, {\"output\": result[\"chat_history\"][1::2]})\n",
    "display_output(result=result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Show me the whole tree structure of opencv directory make sure it include all the files',\n",
       " 'result': 'Here is the tree structure of the OpenCV directory:\\n```\\n/home/roy/Documents/Opencv/\\n.ipynb_checkpoints/\\n6_contour_and_shape_detection-checkpoint.ipynb\\n1_edges_and_gradients.ipynb\\n2_convolutions_and_morphological.ipynb\\n3_blurring_and_thresholding.ipynb\\n4_drawing_and_bitwise.ipynb\\n5_colour_detection.ipynb\\n6_contour_and_shape_detection.ipynb\\n7_mouse_events_and_wrap.ipynb\\n8_haarcascades.ipynb\\nutilities.py\\nassets/\\ncascades/\\nhaarcascade_smile.xml\\nhaarcascade_righteye_2splits.xml\\nhaarcascade_profileface.xml\\nhaarcascade_lowerbody.xml\\nhaarcascade_eye.xml\\nhaarcascade_frontalface_alt.xml\\nhaarcascade_russian_plate_number.xml\\nhaarcascade_fullbody.xml\\nhaarcascade_lefteye_2splits.xml\\nhaarcascade_eye_tree_eyeglasses.xml\\nhaarcascade_frontalcatface.xml\\nhaarcascade_upperbody.xml\\nhaarcascade_frontalface_alt2.xml\\nhaarcascade_frontalcatface_extended.xml\\nhaarcascade_frontalface_alt_tree.xml\\nhaarcascade_car.xml\\nhaarcascade_licence_plate_rus_16stages.xml\\nhaarcascade_frontalface_default.xml\\nimages/\\nshapes.jpg\\nrect.jpg\\nshapes_resize.jpg\\nhello.jpg\\nhello_noise_white.jpg\\nhello_noise_black.jpg\\nscenary.jpg\\nlenna.jpg\\nlamborgini_trackbar.png\\ntransform2.png\\nscharr.png\\nmapped.png\\nblank.png\\nthreshhold_type.png\\npage.jpg\\ncards.jpg\\ncards_points.png\\nopencv_noise.jpg\\nexamples kernels.png\\nfaces_resize.jpg\\nvideos/\\nwalking.avi\\ncars.avi\\noutput.avi\\ndoc.py\\ndataset_lock.lock\\n.folder_structure.md\\n```\\nNote that this tree structure includes all the files and directories mentioned in the provided content. Let me know if you have any further questions!',\n",
       " 'source_documents': [Document(page_content='The following  below content are from the the given file:\\n            [\\n            filename: .folder_structure.md\\n            filepath: /home/roy/Documents/Opencv/.folder_structure.md\\n            content: [And here is the Tree structure of the folder, Use it when asked for relative path or to print tree structure of the folder]\\n            ]\\n\\n\\n\\nThe following  below content are from the the given file:\\n            [\\n            filename: doc.py\\n            filepath: /home/roy/Documents/Opencv/assets/doc.py\\n            content: [# encoding: utf-8\\n# module cv2\\n# from /usr/lib/python3/dist-packages/cv2.cpython-38-x86_64-linux-gnu.so\\n# by generator 1.147\\n\"\"\" Python wrapper for OpenCV. \"\"\"]\\n            ]', metadata={'source': '/home/roy/Documents/Opencv/._folder_files_summary.txt'}),\n",
       "  Document(page_content='The following  below content are from the the given file:\\n            [\\n            filename: .folder_structure.md\\n            filepath: /home/roy/Documents/Opencv/.folder_structure.md', metadata={'source': '/home/roy/Documents/Opencv/._folder_files_summary.txt'}),\n",
       "  Document(page_content='The following  below content are from the the given file:\\n            [\\n            filename: .folder_structure.md\\n            filepath: /home/roy/Documents/Opencv/.folder_structure.md', metadata={'source': '/home/roy/Documents/Opencv/._folder_files_summary.txt'}),\n",
       "  Document(page_content='The following  below content are from the the given file:\\n            [\\n            filename: .folder_structure.md\\n            filepath: /home/roy/Documents/Opencv/.folder_structure.md', metadata={'source': '/home/roy/Documents/Opencv/._folder_files_summary.txt'}),\n",
       "  Document(page_content='The following  below content are from the the given file:\\n            [\\n            filename: .folder_structure.md\\n            filepath: /home/roy/Documents/Opencv/.folder_structure.md', metadata={'source': '/home/roy/Documents/Opencv/._folder_files_summary.txt'}),\n",
       "  Document(page_content='The following  below content are from the the given file:\\n            [\\n            filename: .folder_structure.md\\n            filepath: /home/roy/Documents/Opencv/.folder_structure.md', metadata={'source': '/home/roy/Documents/Opencv/._folder_files_summary.txt'}),\n",
       "  Document(page_content='And here is the Tree structure of the folder, Use it when asked for relative path or to print tree structure of the folder', metadata={'source': '/home/roy/Documents/Opencv/.folder_structure.md'}),\n",
       "  Document(page_content=\"[\\n            filename: .folder_structure.md\\n            filepath: /home/roy/Documents/Opencv/.folder_structure.md\\n            content: ['/home/roy/Documents/Opencv/assets/cascades/haarcascade_smile.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_righteye_2splits.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_profileface.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_lowerbody.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_eye.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_frontalface_alt.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_russian_plate_number.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_fullbody.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_lefteye_2splits.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_eye_tree_eyeglasses.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_frontalcatface.xml']]\\n            ]\", metadata={'source': '/home/roy/Documents/Opencv/._folder_files_summary.txt'}),\n",
       "  Document(page_content='Here is the list global paths of all the file in the directory:', metadata={'source': '/home/roy/Documents/Opencv/.folder_structure.md'}),\n",
       "  Document(page_content=\"['/home/roy/Documents/Opencv/.ipynb_checkpoints/6_contour_and_shape_detection-checkpoint.ipynb', '/home/roy/Documents/Opencv/5_colour_detection.ipynb', '/home/roy/Documents/Opencv/6_contour_and_shape_detection.ipynb', '/home/roy/Documents/Opencv/7_mouse_events_and_wrap.ipynb', '/home/roy/Documents/Opencv/1_edges_and_gradients.ipynb', '/home/roy/Documents/Opencv/2_convolutions_and_morphological.ipynb', '/home/roy/Documents/Opencv/8_haarcascades.ipynb', '/home/roy/Documents/Opencv/utilities.py', '/home/roy/Documents/Opencv/3_blurring_and_thresholding.ipynb', '/home/roy/Documents/Opencv/4_drawing_and_bitwise.ipynb', '/home/roy/Documents/Opencv/dataset_lock.lock', '/home/roy/Documents/Opencv/assets/doc.py', '/home/roy/Documents/Opencv/assets/videos/walking.avi', '/home/roy/Documents/Opencv/assets/videos/cars.avi', '/home/roy/Documents/Opencv/assets/videos/output.avi', '/home/roy/Documents/Opencv/assets/images/shapes.jpg', '/home/roy/Documents/Opencv/assets/images/rect.jpg',\", metadata={'source': '/home/roy/Documents/Opencv/.folder_structure.md'}),\n",
       "  Document(page_content=\"content: [['/home/roy/Documents/Opencv/.ipynb_checkpoints/6_contour_and_shape_detection-checkpoint.ipynb', '/home/roy/Documents/Opencv/5_colour_detection.ipynb', '/home/roy/Documents/Opencv/6_contour_and_shape_detection.ipynb', '/home/roy/Documents/Opencv/7_mouse_events_and_wrap.ipynb', '/home/roy/Documents/Opencv/1_edges_and_gradients.ipynb', '/home/roy/Documents/Opencv/2_convolutions_and_morphological.ipynb', '/home/roy/Documents/Opencv/8_haarcascades.ipynb', '/home/roy/Documents/Opencv/utilities.py', '/home/roy/Documents/Opencv/3_blurring_and_thresholding.ipynb', '/home/roy/Documents/Opencv/4_drawing_and_bitwise.ipynb', '/home/roy/Documents/Opencv/dataset_lock.lock', '/home/roy/Documents/Opencv/assets/doc.py', '/home/roy/Documents/Opencv/assets/videos/walking.avi', '/home/roy/Documents/Opencv/assets/videos/cars.avi', '/home/roy/Documents/Opencv/assets/videos/output.avi', '/home/roy/Documents/Opencv/assets/images/shapes.jpg', '/home/roy/Documents/Opencv/assets/images/rect.jpg',]\\n            ]\", metadata={'source': '/home/roy/Documents/Opencv/._folder_files_summary.txt'}),\n",
       "  Document(page_content=\"'/home/roy/Documents/Opencv/assets/images/transform2.png', '/home/roy/Documents/Opencv/assets/images/scharr.png', '/home/roy/Documents/Opencv/assets/images/mapped.png', '/home/roy/Documents/Opencv/assets/images/blank.png',]\", metadata={'source': '/home/roy/Documents/Opencv/._folder_files_summary.txt'}),\n",
       "  Document(page_content=\"'/home/roy/Documents/Opencv/assets/images/scharr.png', '/home/roy/Documents/Opencv/assets/images/mapped.png', '/home/roy/Documents/Opencv/assets/images/blank.png', '/home/roy/Documents/Opencv/assets/images/threshhold_type.png', '/home/roy/Documents/Opencv/assets/images/page.jpg', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_upperbody.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_frontalface_alt2.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_frontalcatface_extended.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_frontalface_alt_tree.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_car.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_licence_plate_rus_16stages.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_frontalface_default.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_smile.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_righteye_2splits.xml',\", metadata={'source': '/home/roy/Documents/Opencv/.folder_structure.md'}),\n",
       "  Document(page_content='# encoding: utf-8\\n# module cv2\\n# from /usr/lib/python3/dist-packages/cv2.cpython-38-x86_64-linux-gnu.so\\n# by generator 1.147\\n\"\"\" Python wrapper for OpenCV. \"\"\"', metadata={'source': '/home/roy/Documents/Opencv/assets/doc.py'}),\n",
       "  Document(page_content=\"'/home/roy/Documents/Opencv/assets/images/shapes_resize.jpg', '/home/roy/Documents/Opencv/assets/images/hello_noise_white.jpg', '/home/roy/Documents/Opencv/assets/images/hello.jpg', '/home/roy/Documents/Opencv/assets/images/sobel.png', '/home/roy/Documents/Opencv/assets/images/cards.jpg', '/home/roy/Documents/Opencv/assets/images/cards_points.png', '/home/roy/Documents/Opencv/assets/images/opencv_noise.jpg', '/home/roy/Documents/Opencv/assets/images/examples kernels.png', '/home/roy/Documents/Opencv/assets/images/faces_resize.jpg', '/home/roy/Documents/Opencv/assets/images/hello_noise_black.jpg', '/home/roy/Documents/Opencv/assets/images/scenary.jpg', '/home/roy/Documents/Opencv/assets/images/lenna.jpg', '/home/roy/Documents/Opencv/assets/images/lamborgini_trackbar.png', '/home/roy/Documents/Opencv/assets/images/transform2.png', '/home/roy/Documents/Opencv/assets/images/scharr.png', '/home/roy/Documents/Opencv/assets/images/mapped.png', '/home/roy/Documents/Opencv/assets/images/blank.png',\", metadata={'source': '/home/roy/Documents/Opencv/.folder_structure.md'}),\n",
       "  Document(page_content=\"content: ['/home/roy/Documents/Opencv/assets/images/scharr.png', '/home/roy/Documents/Opencv/assets/images/mapped.png', '/home/roy/Documents/Opencv/assets/images/blank.png', '/home/roy/Documents/Opencv/assets/images/threshhold_type.png', '/home/roy/Documents/Opencv/assets/images/page.jpg', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_upperbody.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_frontalface_alt2.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_frontalcatface_extended.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_frontalface_alt_tree.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_car.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_licence_plate_rus_16stages.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_frontalface_default.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_smile.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_righteye_2splits.xml',]\\n            ]\", metadata={'source': '/home/roy/Documents/Opencv/._folder_files_summary.txt'}),\n",
       "  Document(page_content='The following  below content are from the the given file:\\n            [\\n            filename: doc.py\\n            filepath: /home/roy/Documents/Opencv/assets/doc.py\\n            content: [.   #ConnectedComponentsTypes. The data type is CV_32S.\\n    .   @param centroids centroid output for each label, including the background label. Centroids are\\n    .   accessed via centroids(label, 0) for x and centroids(label, 1) for y. The data type CV_64F.\\n    .   @param connectivity 8 or 4 for 8-way or 4-way connectivity respectively\\n    .   @param ltype output image label type. Currently CV_32S and CV_16U are supported.\\n    .   @param ccltype connected components algorithm type (see #ConnectedComponentsAlgorithmsTypes).\\n    \"\"\"\\n    pass]\\n            ]', metadata={'source': '/home/roy/Documents/Opencv/._folder_files_summary.txt'}),\n",
       "  Document(page_content='The following  below content are from the the given file:\\n            [\\n            filename: doc.py\\n            filepath: /home/roy/Documents/Opencv/assets/doc.py\\n            content: [def findContours(image, mode, method, contours=None, hierarchy=None, offset=None): # real signature unknown; restored from __doc__\\n    \"\"\"\\n    findContours(image, mode, method[, contours[, hierarchy[, offset]]]) -> contours, hierarchy\\n    .   @brief Finds contours in a binary image.\\n    .   \\n    .   The function retrieves contours from the binary image using the algorithm @cite Suzuki85 . The contours\\n    .   are a useful tool for shape analysis and object detection and recognition. See squares.cpp in the\\n    .   OpenCV sample directory.\\n    .   @note Since opencv 3.2 source image is not modified by this function.\\n    .   \\n    .   @param image Source, an 8-bit single-channel image. Non-zero pixels are treated as 1\\'s. Zero', metadata={'source': '/home/roy/Documents/Opencv/._folder_files_summary.txt'}),\n",
       "  Document(page_content=\"'/home/roy/Documents/Opencv/assets/cascades/haarcascade_smile.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_righteye_2splits.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_profileface.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_lowerbody.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_eye.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_frontalface_alt.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_russian_plate_number.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_fullbody.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_lefteye_2splits.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_eye_tree_eyeglasses.xml', '/home/roy/Documents/Opencv/assets/cascades/haarcascade_frontalcatface.xml']\", metadata={'source': '/home/roy/Documents/Opencv/.folder_structure.md'}),\n",
       "  Document(page_content='The following  below content are from the the given file:\\n            [\\n            filename: utilities.py\\n            filepath: /home/roy/Documents/Opencv/utilities.py\\n            content: [if os.path.isfile(path) and (path.split(\".\")[-1].split(\"/\")[-1] not in ignore[\"extension\"]) and (path.split(\"/\") not in ignore[\"file\"]):\\n        return path\\n    elif os.path.isdir(path) and path.split(\"/\")[-1] not in ignore[\"dir\"]:\\n        files = []\\n        for p in os.listdir(path):\\n            if os.path.isfile(os.path.join(path, p)) and (p.split(\".\")[-1].split(\"/\")[-1] not in ignore[\"extension\"]) and (p.split(\"/\")[-1] not in ignore[\"file\"]):\\n                files.append(os.path.join(path, p))\\n            elif os.path.isdir(os.path.join(path, p)) and p.split(\"/\")[-1] not in ignore[\"dir\"]:\\n                files.extend(Search2(os.path.join(path, p), ignore=ignore))\\n\\n        if not(relative):\\n            cwd = os.getcwd() + os.path.sep\\n            files = list(map(lambda x: cwd + x, files))', metadata={'source': '/home/roy/Documents/Opencv/._folder_files_summary.txt'})]}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hello Aniruddha!\n",
       "\n",
       "Based on the provided content, here is the tree structure of the OpenCV directory:\n",
       "\n",
       "```\n",
       "/home/roy/Documents/Opencv/\n",
       "├── .folder_structure.md\n",
       "├── 1_edges_and_gradients.ipynb\n",
       "├── 2_convolutions_and_morphological.ipynb\n",
       "├── 3_blurring_and_thresholding.ipynb\n",
       "├── 4_drawing_and_bitwise.ipynb\n",
       "├── 5_colour_detection.ipynb\n",
       "├── 6_contour_and_shape_detection.ipynb\n",
       "├── 7_mouse_events_and_wrap.ipynb\n",
       "├── 8_haarcascades.ipynb\n",
       "├── assets/\n",
       "│   ├── cascades/\n",
       "│   │   ├── haarcascade_eye.xml\n",
       "│   │   ├── haarcascade_eye_tree_eyeglasses.xml\n",
       "│   │   ├── haarcascade_frontalcatface.xml\n",
       "│   │   ├── haarcascade_frontalface_alt.xml\n",
       "│   │   ├── haarcascade_fullbody.xml\n",
       "│   │   ├── haarcascade_lefteye_2splits.xml\n",
       "│   │   ├── haarcascade_lowerbody.xml\n",
       "│   │   ├── haarcascade_profileface.xml\n",
       "│   │   ├── haarcascade_righteye_2splits.xml\n",
       "│   │   └── haarcascade_russian_plate_number.xml\n",
       "│   ├── doc.py\n",
       "│   ├── images/\n",
       "│   │   ├── cards.jpg\n",
       "│   │   ├── faces.jpg\n",
       "│   │   ├── rect.jpg\n",
       "│   │   └── shapes.jpg\n",
       "│   └── videos/\n",
       "│       ├── cars.avi\n",
       "│       ├── output.avi\n",
       "│       └── walking.avi\n",
       "├── utilities.py\n",
       "└── .ipynb_checkpoints/\n",
       "    ├── 6_contour_and_shape_detection-checkpoint.ipynb\n",
       "    └── ... (other checkpoint files)\n",
       "```\n",
       "\n",
       "Note: The `.ipynb_checkpoints` directory may contain more files, but they are not explicitly listed in the provided content. "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"Show me the whole tree structure of opencv directory make sure it include all the files even from subdirectories\"\n",
    "result = qa({\"question\": question})\n",
    "# memory.save_context({\"input\": result[\"chat_history\"][0::2]}, {\"output\": result[\"chat_history\"][1::2]})\n",
    "display_output(result=result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.human.HumanMessage"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result[\"chat_history\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hello Aniruddha!\n",
       "\n",
       "I'd be happy to help you with the tree structure of the OpenCV directory. Based on the provided file content, here is the tree structure:\n",
       "\n",
       "```\n",
       "/home/roy/Documents/Opencv/\n",
       "|- .folder_structure.md\n",
       "|- assets/\n",
       "|  |- doc.py\n",
       "|  |- images/\n",
       "|  |  |- shapes.jpg\n",
       "|  |  |- hello_noise_white.jpg\n",
       "|  |  |- examples kernels.png\n",
       "|  |- cascades/\n",
       "|  |  |- haarcascade_smile.xml\n",
       "|  |  |- haarcascade_righteye_2splits.xml\n",
       "|  |  |- haarcascade_profileface.xml\n",
       "|  |  |- haarcascade_lowerbody.xml\n",
       "|  |  |- haarcascade_eye.xml\n",
       "|  |  |- haarcascade_frontalface_alt.xml\n",
       "|  |  |- haarcascade_russian_plate_number.xml\n",
       "|  |  |- haarcascade_fullbody.xml\n",
       "|  |  |- haarcascade_lefteye_2splits.xml\n",
       "|  |  |- haarcascade_eye_tree_eyeglasses.xml\n",
       "|  |  |- haarcascade_frontalcatface.xml\n",
       "|- 2_convolutions_and_morphological.ipynb\n",
       "|- 6_contour_and_shape_detection-checkpoint.ipynb\n",
       "|- 8_haarcascades.ipynb\n",
       "|- utilities.py\n",
       "```\n",
       "\n",
       "I've included all the files and subdirectories mentioned in the provided content. Let me know if you have any further questions!\n",
       "\n",
       "And, yes, I remember your name: Aniruddha! "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"Now did you remember my name?\"\n",
    "result = qa({\"question\": question})\n",
    "display_output(result=result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the provided file contents, here is the tree structure of the OpenCV directory:\n",
       "\n",
       "```\n",
       "/home/roy/Documents/Opencv/\n",
       "assets/\n",
       "doc.py\n",
       "folder_structure.md\n",
       "utilities.py\n",
       "2_convolutions_and_morphological.ipynb\n",
       "6_contour_and_shape_detection-checkpoint.ipynb\n",
       ".ipynb_checkpoints/\n",
       "6_contour_and_shape_detection-checkpoint.ipynb\n",
       "```\n",
       "\n",
       "Please note that this structure only includes the files and directories mentioned in the provided file contents. If there are other files or directories in the OpenCV directory, they are not included in this structure. "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"Again doing same thing why don't you show me whole structure?\"\n",
    "result = qa({\"question\": question})\n",
    "display_output(result=result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
